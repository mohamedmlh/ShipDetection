{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYOUG0HdqU1r"
   },
   "outputs": [],
   "source": [
    "#pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export KAGGLE_USERNAME=mohamedmalhou\n",
    "#!export KAGGLE_KEY=77cb5e2e17b8d6b9ab875c1d636404b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download airbus-ship-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm airbus-ship-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fCEccuadqjDW",
    "outputId": "003feca8-2e06-4da4-c9e7-21c05513b701"
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions list -s airBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "DuMzUCIY9gnf",
    "outputId": "58363c8b-114c-414d-8f0a-995e583c8872"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import signal\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os \n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9rERcGhT9LFJ",
    "outputId": "3f5e68ed-5c6a-498f-ae40-f3be6654e9ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWKprJca9H72"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"\"\n",
    "size = 768\n",
    "import PIL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nwIpUo068Ao"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(mypath + \"train_ship_segmentations_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFkyMujq9UOH"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df['ship_count'] = df.groupby('ImageId')['ImageId'].transform('count')\n",
    "df.loc[df['EncodedPixels'].isnull().values,'ship_count'] = 0  #see infocusp's comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "wEfnOeju9WvT",
    "outputId": "a7ec59db-6dcb-4d69-cea4-7bf99ffdb5d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.distplot(df['ship_count'],kde=False)\n",
    "plt.title('Ship Count Distribution in Train Set')\n",
    "\n",
    "print(df['ship_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "r4BzvCBh9nG9",
    "outputId": "0a9ebd9f-2468-40cb-9cbd-5e5f1e478c16"
   },
   "outputs": [],
   "source": [
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQa-KSJL-E6T"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_ids = df.ImageId.values\n",
    "df = df.set_index('ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9aVkXgOGalI"
   },
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "def masks_as_image(in_mask_list, all_masks=None,size = 768):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    if all_masks is None:\n",
    "        all_masks = np.zeros((size, size), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    print(mask_rle)\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "def rle_decode_crop(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    size = 768\n",
    "    X,Y = 0,0\n",
    "    count = 0\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        count+=(hi-lo)\n",
    "        i,j = lo//size, lo%size\n",
    "        X+=i*(hi-lo)\n",
    "        Y+=j*(hi-lo) + (hi-lo+1)*(hi-lo)//2\n",
    "        img[lo:hi] = 1\n",
    "        \n",
    "    return (img.reshape(shape).T,X//count,Y//count)  # Needed to align to RLE direction\n",
    "def masks_as_image_crop(in_mask_list, all_masks=None,size = 768):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    if all_masks is None:\n",
    "        all_masks = np.zeros((size, size), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    \n",
    "    centers = []\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            Mask,i,j = rle_decode_crop(mask)\n",
    "            all_masks += Mask\n",
    "            centers.append((i,j))\n",
    "   \n",
    "    return (np.expand_dims(all_masks, -1), centers)\n",
    "def dist(i,j,x,y):\n",
    "    return ((i-x)**2 + (j-y)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPUujLFiHTpw"
   },
   "outputs": [],
   "source": [
    "\n",
    "mypath = \"\"\n",
    "trainfiles = listdir(  \"train_v2\") \n",
    "print(len(trainfiles))\n",
    "\n",
    "testfiles = listdir(\"test_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxxX5HSoHsi_"
   },
   "outputs": [],
   "source": [
    "load_img = lambda filename: np.array(PIL.Image.open(f\"train_v2/{filename}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#split image into 4 by 4\n",
    "trdata = []\n",
    "i = 0\n",
    "\n",
    "for filename in trainfiles[60000:120000] : \n",
    "  if i%10000 == 0:\n",
    "    print(\"iteration \",i)\n",
    "  i+=1\n",
    "  if df.query('ImageId==\"'+filename+'\"')['ship_count'][0] >=1 :\n",
    "    im = load_img(filename)\n",
    "    ma = masks_as_image(df.query('ImageId==\"'+filename+'\"')['EncodedPixels'])\n",
    "    for k in range(4):\n",
    "        for l in range(4):\n",
    "            trdata.append((im[224*k - 43*k: 224*(k+1)-43*k, 224*l - 43*l: 224*(l+1) - 43*l],\n",
    "                           ma[224*k - 43*k: 224*(k+1)-43*k, 224*l - 43*l: 224*(l+1) - 43*l]))\n",
    "    #trdata.append((resize(load_img(filename),(224,224)),\n",
    "                  #resize(masks_as_image(df.query('ImageId==\"'+filename+'\"')['EncodedPixels']),(224,224))))\n",
    "                  \n",
    "tsdata = []\n",
    "\n",
    "for filename in trainfiles[120000:122000] : \n",
    "  if i%1000 == 0:\n",
    "    print(\"iteration \",i)\n",
    "  i+=1\n",
    "  if df.query('ImageId==\"'+filename+'\"')['ship_count'][0] >=1 :\n",
    "    tsdata.append((resize(load_img(filename),(224,224)),\n",
    "                   resize(masks_as_image(df.query('ImageId==\"'+filename+'\"')['EncodedPixels']),(224,224))))\n",
    "\"\"\"\n",
    "trdata = []\n",
    "Original = []\n",
    "og = 768\n",
    "s = 224\n",
    "counter = 0\n",
    "for filename in trainfiles[180000:189000] : \n",
    "\n",
    "  counter+=1\n",
    "  if counter%1000 ==0:\n",
    "        print(\"iteration \", counter)\n",
    "  if df.query('ImageId==\"'+filename+'\"')['ship_count'][0] >=1 :\n",
    "    im = load_img(filename)\n",
    "    ma,centers = masks_as_image_crop(df.query('ImageId==\"'+filename+'\"')['EncodedPixels'])\n",
    "    for k in range(len(centers)):\n",
    "        j,i = centers[k]\n",
    "        intersects = False\n",
    "        for m,n in centers[:k]:\n",
    "            if dist(j,i,m,n) <56 :\n",
    "                intersects = True\n",
    "        if not intersects :\n",
    "            trdata.append((im[max(i-s//2,0)-max(i+s//2-og,0):min(og,i+s//2) + max(0,s//2-i),\n",
    "                          max(j-s//2,0)-max(j+s//2-og,0):min(og,j+s//2) + max(0,s//2-j)],\n",
    "                       ma[max(i-s//2,0)-max(i+s//2-og,0):min(og,i+s//2) + max(0,s//2-i),\n",
    "                          max(j-s//2,0)-max(j+s//2-og,0):min(og,j+s//2) + max(0,s//2-j)]))\n",
    "    #Original.append((im,ma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oF5twm0BHvxy"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(x,size = 224):\n",
    "  num_examples = len(x)\n",
    "  \n",
    "  Y = np.zeros((num_examples, size, size, 1), dtype=np.int32)\n",
    "  X = np.zeros((num_examples, size, size, 3), dtype=np.int32)\n",
    "  for i in range(num_examples):\n",
    "    im,pixels = x[i]\n",
    "    Y[i,...] = pixels\n",
    "    X[i,...] = im\n",
    "  print(\"X shape is \",X.shape)\n",
    "  return X, Y\n",
    "def prepare_dataloader(X_train, y_train, batch_size):\n",
    "  \n",
    "\n",
    "  trainset = torch.utils.data.TensorDataset(torch.tensor(np.transpose(X_train, (0, 3, 1, 2))),\n",
    "                                            torch.tensor(y_train[..., 0]))\n",
    " \n",
    "  trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "\n",
    "  return trainloader\n",
    "#print(len(trdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = prepare_dataloader(*prepare_dataset(trdata),16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = prepare_dataloader(*prepare_dataset(tsdata),16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "0aAqMf4tIqVY",
    "outputId": "5ca67586-a3f4-4cca-d410-acbcb321ac76"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "  def __init__(self, in_planes, planes, stride=1,id = 1):\n",
    "    super(ResNetBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(\n",
    "        in_planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self._id_ = nn.Sequential()\n",
    "    if stride != 1:\n",
    "      self._id_ = nn.Conv2d(\n",
    "          in_planes, planes, kernel_size=3, stride=2, padding=1)\n",
    "    if id != 1:\n",
    "      self._id_ = nn.Conv2d(\n",
    "          in_planes, planes, kernel_size=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "      #print(\"x is \", x.size())\n",
    "      x_id = self._id_(x)\n",
    "      #print(\"id x is \", x_id.size())\n",
    "      bx = F.relu(self.bn1(self.conv1(x)))\n",
    "      #print(\"bx is \",bx.size())\n",
    "      bx = F.relu(self.bn2(self.conv2(bx)) + x_id)\n",
    "\n",
    "      return bx\n",
    "\n",
    "\n",
    "class U_ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_filters=16, input_dim=1, image_size=64):\n",
    "        super(U_ResNet, self).__init__()\n",
    "        self.in_planes = num_filters\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_dim, num_filters,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.R1 = self._make_layer(block, self.in_planes, 2, 1,1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.id1 = nn.Sequential()\n",
    "        self.R2 = self._make_layer(block, 2*self.in_planes, 2, 2,1)\n",
    "        self.in_planes*=2\n",
    "        self.bn3 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.R3 = self._make_layer(block, 2*self.in_planes, 2, 2,1)\n",
    "        self.in_planes*=2\n",
    "        self.bn4 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.deconv1 = nn.ConvTranspose2d(self.in_planes, self.in_planes//2, 2, stride=2)\n",
    "        \n",
    "        self.R4 = self._make_layer(block, self.in_planes//2, num_blocks[0], 1,2)\n",
    "        self.in_planes//=2\n",
    "        self.deconv2 = nn.ConvTranspose2d(self.in_planes, self.in_planes//2, 2, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(self.in_planes//2)\n",
    "        self.R5 = self._make_layer(block, self.in_planes//2, num_blocks[1], 1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(num_filters)\n",
    "        self.conv2 = nn.Conv2d(num_filters, 2, kernel_size=1)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride,_id):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride,_id))\n",
    "        for _ in range(num_blocks-1):\n",
    "          layers.append(block(planes, planes, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "       \n",
    "        out = self.bn2(self.R1(out))\n",
    "        \n",
    "        concat1 = self.id1(out)\n",
    "       \n",
    "        out = self.bn3(self.R2(out))\n",
    "       \n",
    "        concat2 = self.id1(out)\n",
    "        \n",
    "        out = self.bn4(self.R3(out))\n",
    "       \n",
    "        out = self.deconv1(out)\n",
    "        \n",
    "        #print(concat2.size(),out.size())\n",
    "        out = self.R4(torch.cat((concat2, out), dim=1))\n",
    "       \n",
    "        out = self.bn5(self.deconv2(out))\n",
    "        #print(\"deconv2\" , out.size())\n",
    "        #print(\"id2 \" , concat1.size())\n",
    "   \n",
    "        out = torch.cat((concat1, out), dim=1)\n",
    "        #print(\"concat \", out.size())\n",
    "      \n",
    "        out = self.bn6(self.R5(out))\n",
    "       \n",
    "        #print(\"out of R5 is \" , out.size() )\n",
    "        out = self.conv2(out)\n",
    "      \n",
    "        return out\n",
    "\n",
    "def U_resNet():\n",
    "    return U_ResNet(ResNetBlock, [2, 2],input_dim=3,image_size=768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossBinary:\n",
    "    \"\"\"\n",
    "     Implementation from  https://github.com/ternaus/robot-surgery-segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, jaccard_weight=0):\n",
    "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
    "        self.jaccard_weight = jaccard_weight\n",
    "\n",
    "    def __call__(self, outputs, targets):\n",
    "        loss = self.nll_loss(outputs, targets)\n",
    "\n",
    "        if self.jaccard_weight:\n",
    "            eps = 1e-15\n",
    "            jaccard_target = (targets == 1.0).float()\n",
    "            jaccard_output = F.sigmoid(outputs)\n",
    "\n",
    "            intersection = (jaccard_output * jaccard_target).sum()\n",
    "            union = jaccard_output.sum() + jaccard_target.sum()\n",
    "\n",
    "            loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3pEwRF1LlDP"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "not used anymore\n",
    "a = 0.5 / (224*224-20*30)\n",
    "b = 0.5 / (20*30)\n",
    "c = a+b\n",
    "a /= c\n",
    "b /= c\n",
    "weights = [b,a]\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "\"\"\"\n",
    "detection_criterion = nn.CrossEntropyLoss()#weight=class_weights)#LossBinary(jaccard_weight=5)\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "def acc(predicted, labels):\n",
    "  return (predicted == labels).sum().item()/labels.size(0)\n",
    "\n",
    "\n",
    "\n",
    "def IoU(predicted, labels):\n",
    "  inter = (predicted & labels).float().sum((1, 2))  \n",
    "  union = (predicted | labels).float().sum((1, 2)) \n",
    "  iou = inter / union\n",
    "  \n",
    "  iou = float(iou.sum().item()/labels.size(0))\n",
    "  \n",
    "  return iou\n",
    "\n",
    "def accuracy(net, test_loader, cuda=True, metric=acc):\n",
    "  net.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  loss = 0\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          images, labels = data\n",
    "          if cuda:\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "          outputs = net(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += 1\n",
    "          correct += metric(predicted, labels)\n",
    "\n",
    "  net.train()\n",
    "  print('Accuracy of the network on the test images: %d %%' % (\n",
    "      100 * correct / (total+1)))\n",
    "  # return (100.0 * correct / total, loss/total)\n",
    "  return 100.0 * correct\n",
    "\n",
    "\n",
    "\n",
    "def train(net, optimizer, criterion, train_loader, test_loader,  n_epoch = 5,\n",
    "          train_acc_period = 1000,\n",
    "          test_acc_period = 500,\n",
    "          cuda=True,\n",
    "          metric=acc):\n",
    "  loss_train = []\n",
    "  loss_test = []\n",
    "  total = 0\n",
    "  for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "      if epoch%4==1:\n",
    "        torch.save(net,\"net_satisfactoryB_epoch\"+str(epoch)+\".pt\")\n",
    "      print(\"epoch : \", epoch)\n",
    "      running_loss = 0.0\n",
    "      running_acc = 0.0\n",
    "      for i, data in enumerate(train_loader, 0):\n",
    "          # get the inputs\n",
    "          inputs, labels = data\n",
    "          \n",
    "          if cuda:\n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "       \n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "   \n",
    "          outputs = net(inputs)\n",
    "\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          total += labels.size(0)\n",
    "     \n",
    "          running_loss = 0.33*loss.item() + 0.66*running_loss #/float(labels.size(0))\n",
    "\n",
    "\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          correct = metric(predicted, labels)\n",
    "       \n",
    "          running_acc = 0.3*correct + 0.66*running_acc\n",
    "\n",
    "          if i % train_acc_period == train_acc_period-1:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss))\n",
    "            print('[%d, %5d] acc: %.3f' %(epoch + 1, i + 1, running_acc))\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            # break\n",
    "      if epoch % test_acc_period == test_acc_period-1:\n",
    "          print('u')\n",
    "          cur_acc = accuracy(net, test_loader, cuda=cuda, metric=metric)\n",
    "          print('[%d] test acc: %.3f' %(epoch + 1, cur_acc))\n",
    "\n",
    "  print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "Pje9ksPhMlr9",
    "outputId": "ed53a19c-abe1-4583-e018-5e3f5f95618b"
   },
   "outputs": [],
   "source": [
    "net = U_resNet()\n",
    "#net = torch.load(\"net_loss0.001_ep12.pt\")\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    net.cuda()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "testloader = []\n",
    "train(net,\n",
    "      optimizer,\n",
    "      detection_criterion,\n",
    "      trainloader,\n",
    "      testloader,\n",
    "      n_epoch = 30,\n",
    "      cuda=use_cuda,\n",
    "      train_acc_period = 30,\n",
    "      test_acc_period = 30,\n",
    "      metric=IoU)\n",
    "\n",
    "#accuracy(net, test_loader=testloader, cuda=use_cuda, metric=IoU)\n",
    "\n",
    "detection_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(net, test_loader=testloader,cuda = use_cuda, metric=IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net,\"net_satisfactory_epoch28.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(64,64))\n",
    "for i in range(5):\n",
    "    #filename = trainfiles[56054]#30594\n",
    "    #img = resize(load_img(filename),(224,224))\n",
    "    I,M = trdata[5*i+4]\n",
    "    mask = M[:,:,0]#masks_as_image(df.query('ImageId==\"'+filename+'\"')['EncodedPixels'])[:,:,0]\n",
    "    img = I\n",
    "    input = torch.Tensor(np.transpose(np.expand_dims(img,axis=0),(0, 3, 1, 2)))\n",
    "    input = input.type(torch.cuda.FloatTensor)\n",
    "    with torch.no_grad():\n",
    "        lab = net(input)\n",
    "    _, predicted = torch.max(lab.data, 1)\n",
    "\n",
    "    l = predicted.type(torch.LongTensor).data.numpy()\n",
    "    \n",
    "    L = l[0]\n",
    "\n",
    "    np.amax(mask)\n",
    "\n",
    "    fig.add_subplot(5, 3,i*3+ 1)\n",
    "    plt.imshow(img)\n",
    "    fig.add_subplot(5, 3,i*3+ 2)\n",
    "    plt.imshow(mask)\n",
    "    fig.add_subplot(5, 3, i*3+3)\n",
    "    plt.imshow(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net  = torch.load('net_satisfactory_epoch28.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdata = []\n",
    "\n",
    "og = 768\n",
    "s = 224\n",
    "counter = 0\n",
    "for filename in trainfiles[140000:148000] : \n",
    "\n",
    "  counter+=1\n",
    "  if counter%1000 ==0:\n",
    "        print(\"iteration \", counter)\n",
    "  if df.query('ImageId==\"'+filename+'\"')['ship_count'][0] >=1 :\n",
    "    im = load_img(filename)\n",
    "    ma,centers = masks_as_image_crop(df.query('ImageId==\"'+filename+'\"')['EncodedPixels'])\n",
    "    for k in range(len(centers)):\n",
    "        j,i = centers[k]\n",
    "        intersects = False\n",
    "        for m,n in centers[:k]:\n",
    "            if dist(j,i,m,n) <56 :\n",
    "                intersects = True\n",
    "        if not intersects :\n",
    "            tsdata.append((im[max(i-s//2,0)-max(i+s//2-og,0):min(og,i+s//2) + max(0,s//2-i),\n",
    "                          max(j-s//2,0)-max(j+s//2-og,0):min(og,j+s//2) + max(0,s//2-j)],\n",
    "                       ma[max(i-s//2,0)-max(i+s//2-og,0):min(og,i+s//2) + max(0,s//2-i),\n",
    "                          max(j-s//2,0)-max(j+s//2-og,0):min(og,j+s//2) + max(0,s//2-j)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = prepare_dataloader(*prepare_dataset(tsdata),16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "for i in range(4,29,4):\n",
    "    net  = torch.load(f'net_satisfactory_epoch{i}.pt')\n",
    "    print(\"epoch \",i)\n",
    "    accuracy(net, test_loader=testloader, cuda=use_cuda, metric=IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,36,50,49,55,53,58,55]\n",
    "plt.plot(range(0,29,4),l)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"success rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_imgT = lambda filename: np.array(PIL.Image.open(f\"test_v2/{filename}\"))\n",
    "tsdata = []\n",
    "\n",
    "og = 768\n",
    "s = 224\n",
    "counter = 0\n",
    "for filename in testfiles[2:3] : \n",
    "\n",
    "    counter+=1\n",
    "    if counter%1000 ==0:\n",
    "        print(\"iteration \", counter)\n",
    "  \n",
    "    im = load_imgT(filename)\n",
    "    #plt.imshow(im)\n",
    "    tsdata.append(im)\n",
    "    MASK = np.zeros((og,og))\n",
    "    for k in range(4):\n",
    "        for l in range(4):\n",
    "            img = im[224*k - 43*k: 224*(k+1)-43*k, 224*l - 43*l: 224*(l+1) - 43*l]\n",
    "            #tsdata.append(img)\n",
    "            input = torch.Tensor(np.transpose(np.expand_dims(img,axis=0),(0, 3, 1, 2)))\n",
    "            input = input.type(torch.cuda.FloatTensor)\n",
    "            with torch.no_grad():\n",
    "                lab = net(input)\n",
    "            _, predicted = torch.max(lab.data, 1)\n",
    "\n",
    "            L = predicted.type(torch.LongTensor).data.numpy()\n",
    "            \n",
    "            MASK[224*k - 43*k: 224*(k+1)-43*k, 224*l - 43*l: 224*(l+1) - 43*l] += L[0]\n",
    "    MASK = MASK//2\n",
    "    plt.imshow(MASK,cmap='gray')\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tsdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(64,64))\n",
    "for i in range(16):\n",
    "    #filename = trainfiles[56054]#30594\n",
    "    #img = resize(load_img(filename),(224,224))\n",
    "    img = tsdata[5*i+4]\n",
    "   \n",
    "    \n",
    "    input = torch.Tensor(np.transpose(np.expand_dims(img,axis=0),(0, 3, 1, 2)))\n",
    "    input = input.type(torch.cuda.FloatTensor)\n",
    "    with torch.no_grad():\n",
    "        lab = net(input)\n",
    "    _, predicted = torch.max(lab.data, 1)\n",
    "\n",
    "    l = predicted.type(torch.LongTensor).data.numpy()\n",
    "    \n",
    "    L = l[0]\n",
    "\n",
    "   \n",
    "\n",
    "    fig.add_subplot(5, '2',i*2+ 1)\n",
    "    plt.imshow(img)\n",
    "    fig.add_subplot(5, 2, i*2+2)\n",
    "    plt.imshow(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        ## Mettre un max-pooling \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "def alexnet(num_classes, pretrained=False, **kwargs):\n",
    "    model = AlexNet(1000,**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))  ### checker comment se fait la copie\n",
    "        for p in model.features.parameters():\n",
    "            p.requires_grad=False\n",
    "    model.classifier=AlexNet(2,**kwargs).classifier\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex = torch.load(\"classifier_epoch7.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata = []\n",
    "Testdata = []\n",
    "og = 768\n",
    "s = 224\n",
    "counter1 = 0\n",
    "counter2=0\n",
    "nber_files=15000\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "   \n",
    "for filename in trainfiles[nber_files:nber_files + 10000]:\n",
    "    im = load_img(filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if df.query('ImageId==\"'+filename+'\"')['ship_count'][0] >=1:\n",
    "        count1+=1\n",
    "        Testdata.append((torch.Tensor(im).permute(2,0,1),1))\n",
    "        if count1>=1500 :\n",
    "            break\n",
    "    else :\n",
    "        if count2>=1500 :\n",
    "            if count1%100 ==0 :\n",
    "                print(\"count2 acheived\")\n",
    "                print(\"count 1 is \", count1)\n",
    "            continue\n",
    "        count2+=1\n",
    "        Testdata.append((torch.Tensor(im).permute(2,0,1),0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader=torch.utils.data.DataLoader(Testdata,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "def accuracyMC(net, test_loader, cuda=True):\n",
    "  net.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  loss = 0\n",
    "  confusion_matrix = [[0,0],[0,0]]\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          images, labels = data\n",
    "          \n",
    "          if cuda:\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "          outputs = net(images)\n",
    "          # loss+= criterion(outputs, labels).item()\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          for i in range(labels.size(0)):\n",
    "            confusion_matrix[labels[i].item()][predicted[i].item()] +=1\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          \n",
    "  print(confusion_matrix)\n",
    "  return 100.0 * correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyMC(alex,testloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ship_detection_Uresnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
